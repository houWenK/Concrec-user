{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48ec2482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7526f0a8",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85f73b1",
   "metadata": {},
   "source": [
    "f(a, b) = 3a - 2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "075722dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_vec = np.random.randint(10, size=1000)\n",
    "b_vec = np.random.randint(10, size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "996dd1d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 5, 7, 1, 1, 3, 8, 5, 5, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_vec[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88c3da12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 8, 2, 2, 5, 4, 2, 7, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_vec[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72c7ef32",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_vec = a_vec * 3 - b_vec * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "053cc6b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9, 13,  5, -1, -1, -1, 16, 11,  1,  3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_vec[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b4d3e0",
   "metadata": {},
   "source": [
    "## keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f62e4f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d873edac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-19 10:49:35.219290: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(1, input_dim=2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b06fb382",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='mean_squared_error'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e817f4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.stack([a_vec, b_vec], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b5e1115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 0],\n",
       "       [5, 1],\n",
       "       [7, 8]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "236584b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel/Programs/machine-learning/recsys-lecture/concrec/rank-service/venv/lib/python3.8/site-packages/pandas/compat/__init__.py:124: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "2021-11-19 10:51:50.403950: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "32/32 [==============================] - 0s 900us/step - loss: 115.2395\n",
      "Epoch 2/300\n",
      "32/32 [==============================] - 0s 779us/step - loss: 112.5795\n",
      "Epoch 3/300\n",
      "32/32 [==============================] - 0s 689us/step - loss: 110.0921\n",
      "Epoch 4/300\n",
      "32/32 [==============================] - 0s 776us/step - loss: 107.5245\n",
      "Epoch 5/300\n",
      "32/32 [==============================] - 0s 628us/step - loss: 105.0854\n",
      "Epoch 6/300\n",
      "32/32 [==============================] - 0s 739us/step - loss: 102.6944\n",
      "Epoch 7/300\n",
      "32/32 [==============================] - 0s 673us/step - loss: 100.3250\n",
      "Epoch 8/300\n",
      "32/32 [==============================] - 0s 678us/step - loss: 97.9190\n",
      "Epoch 9/300\n",
      "32/32 [==============================] - 0s 667us/step - loss: 95.5985\n",
      "Epoch 10/300\n",
      "32/32 [==============================] - 0s 727us/step - loss: 93.2836\n",
      "Epoch 11/300\n",
      "32/32 [==============================] - 0s 769us/step - loss: 91.0324\n",
      "Epoch 12/300\n",
      "32/32 [==============================] - 0s 867us/step - loss: 88.8518\n",
      "Epoch 13/300\n",
      "32/32 [==============================] - 0s 739us/step - loss: 86.6274\n",
      "Epoch 14/300\n",
      "32/32 [==============================] - 0s 745us/step - loss: 84.5060\n",
      "Epoch 15/300\n",
      "32/32 [==============================] - 0s 666us/step - loss: 82.4187\n",
      "Epoch 16/300\n",
      "32/32 [==============================] - 0s 648us/step - loss: 80.2643\n",
      "Epoch 17/300\n",
      "32/32 [==============================] - 0s 649us/step - loss: 78.2095\n",
      "Epoch 18/300\n",
      "32/32 [==============================] - 0s 706us/step - loss: 76.1242\n",
      "Epoch 19/300\n",
      "32/32 [==============================] - 0s 657us/step - loss: 74.0170\n",
      "Epoch 20/300\n",
      "32/32 [==============================] - 0s 652us/step - loss: 72.0337\n",
      "Epoch 21/300\n",
      "32/32 [==============================] - 0s 676us/step - loss: 70.1234\n",
      "Epoch 22/300\n",
      "32/32 [==============================] - 0s 627us/step - loss: 68.2286\n",
      "Epoch 23/300\n",
      "32/32 [==============================] - 0s 666us/step - loss: 66.3214\n",
      "Epoch 24/300\n",
      "32/32 [==============================] - 0s 765us/step - loss: 64.3746\n",
      "Epoch 25/300\n",
      "32/32 [==============================] - 0s 624us/step - loss: 62.5061\n",
      "Epoch 26/300\n",
      "32/32 [==============================] - 0s 675us/step - loss: 60.6837\n",
      "Epoch 27/300\n",
      "32/32 [==============================] - 0s 700us/step - loss: 58.8801\n",
      "Epoch 28/300\n",
      "32/32 [==============================] - 0s 749us/step - loss: 57.1173\n",
      "Epoch 29/300\n",
      "32/32 [==============================] - 0s 823us/step - loss: 55.3353\n",
      "Epoch 30/300\n",
      "32/32 [==============================] - 0s 801us/step - loss: 53.5729\n",
      "Epoch 31/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 51.9104\n",
      "Epoch 32/300\n",
      "32/32 [==============================] - 0s 731us/step - loss: 50.2920\n",
      "Epoch 33/300\n",
      "32/32 [==============================] - 0s 675us/step - loss: 48.6435\n",
      "Epoch 34/300\n",
      "32/32 [==============================] - 0s 686us/step - loss: 47.0665\n",
      "Epoch 35/300\n",
      "32/32 [==============================] - 0s 657us/step - loss: 45.4680\n",
      "Epoch 36/300\n",
      "32/32 [==============================] - 0s 675us/step - loss: 43.8924\n",
      "Epoch 37/300\n",
      "32/32 [==============================] - 0s 720us/step - loss: 42.3418\n",
      "Epoch 38/300\n",
      "32/32 [==============================] - 0s 663us/step - loss: 40.8433\n",
      "Epoch 39/300\n",
      "32/32 [==============================] - 0s 804us/step - loss: 39.4147\n",
      "Epoch 40/300\n",
      "32/32 [==============================] - 0s 655us/step - loss: 37.9486\n",
      "Epoch 41/300\n",
      "32/32 [==============================] - 0s 746us/step - loss: 36.5315\n",
      "Epoch 42/300\n",
      "32/32 [==============================] - 0s 733us/step - loss: 35.1121\n",
      "Epoch 43/300\n",
      "32/32 [==============================] - 0s 644us/step - loss: 33.7332\n",
      "Epoch 44/300\n",
      "32/32 [==============================] - 0s 801us/step - loss: 32.3744\n",
      "Epoch 45/300\n",
      "32/32 [==============================] - 0s 675us/step - loss: 31.0377\n",
      "Epoch 46/300\n",
      "32/32 [==============================] - 0s 663us/step - loss: 29.8043\n",
      "Epoch 47/300\n",
      "32/32 [==============================] - 0s 642us/step - loss: 28.5899\n",
      "Epoch 48/300\n",
      "32/32 [==============================] - 0s 716us/step - loss: 27.3004\n",
      "Epoch 49/300\n",
      "32/32 [==============================] - 0s 660us/step - loss: 26.0557\n",
      "Epoch 50/300\n",
      "32/32 [==============================] - 0s 699us/step - loss: 24.9205\n",
      "Epoch 51/300\n",
      "32/32 [==============================] - 0s 678us/step - loss: 23.7776\n",
      "Epoch 52/300\n",
      "32/32 [==============================] - 0s 623us/step - loss: 22.6138\n",
      "Epoch 53/300\n",
      "32/32 [==============================] - 0s 831us/step - loss: 21.5418\n",
      "Epoch 54/300\n",
      "32/32 [==============================] - 0s 690us/step - loss: 20.4768\n",
      "Epoch 55/300\n",
      "32/32 [==============================] - 0s 888us/step - loss: 19.4390\n",
      "Epoch 56/300\n",
      "32/32 [==============================] - 0s 742us/step - loss: 18.4096\n",
      "Epoch 57/300\n",
      "32/32 [==============================] - 0s 640us/step - loss: 17.4007\n",
      "Epoch 58/300\n",
      "32/32 [==============================] - 0s 751us/step - loss: 16.4517\n",
      "Epoch 59/300\n",
      "32/32 [==============================] - 0s 755us/step - loss: 15.5208\n",
      "Epoch 60/300\n",
      "32/32 [==============================] - 0s 633us/step - loss: 14.6394\n",
      "Epoch 61/300\n",
      "32/32 [==============================] - 0s 736us/step - loss: 13.7639\n",
      "Epoch 62/300\n",
      "32/32 [==============================] - 0s 675us/step - loss: 12.9247\n",
      "Epoch 63/300\n",
      "32/32 [==============================] - 0s 656us/step - loss: 12.1130\n",
      "Epoch 64/300\n",
      "32/32 [==============================] - 0s 692us/step - loss: 11.3067\n",
      "Epoch 65/300\n",
      "32/32 [==============================] - 0s 635us/step - loss: 10.5509\n",
      "Epoch 66/300\n",
      "32/32 [==============================] - 0s 709us/step - loss: 9.8107\n",
      "Epoch 67/300\n",
      "32/32 [==============================] - 0s 635us/step - loss: 9.0834\n",
      "Epoch 68/300\n",
      "32/32 [==============================] - 0s 648us/step - loss: 8.3996\n",
      "Epoch 69/300\n",
      "32/32 [==============================] - 0s 650us/step - loss: 7.7386\n",
      "Epoch 70/300\n",
      "32/32 [==============================] - 0s 641us/step - loss: 7.1270\n",
      "Epoch 71/300\n",
      "32/32 [==============================] - 0s 684us/step - loss: 6.5285\n",
      "Epoch 72/300\n",
      "32/32 [==============================] - 0s 632us/step - loss: 5.9488\n",
      "Epoch 73/300\n",
      "32/32 [==============================] - 0s 639us/step - loss: 5.3954\n",
      "Epoch 74/300\n",
      "32/32 [==============================] - 0s 643us/step - loss: 4.8721\n",
      "Epoch 75/300\n",
      "32/32 [==============================] - 0s 628us/step - loss: 4.3733\n",
      "Epoch 76/300\n",
      "32/32 [==============================] - 0s 639us/step - loss: 3.8986\n",
      "Epoch 77/300\n",
      "32/32 [==============================] - 0s 621us/step - loss: 3.4539\n",
      "Epoch 78/300\n",
      "32/32 [==============================] - 0s 675us/step - loss: 3.0388\n",
      "Epoch 79/300\n",
      "32/32 [==============================] - 0s 652us/step - loss: 2.6596\n",
      "Epoch 80/300\n",
      "32/32 [==============================] - 0s 619us/step - loss: 2.3131\n",
      "Epoch 81/300\n",
      "32/32 [==============================] - 0s 680us/step - loss: 1.9802\n",
      "Epoch 82/300\n",
      "32/32 [==============================] - 0s 662us/step - loss: 1.6817\n",
      "Epoch 83/300\n",
      "32/32 [==============================] - 0s 659us/step - loss: 1.4089\n",
      "Epoch 84/300\n",
      "32/32 [==============================] - 0s 664us/step - loss: 1.1517\n",
      "Epoch 85/300\n",
      "32/32 [==============================] - 0s 634us/step - loss: 0.9228\n",
      "Epoch 86/300\n",
      "32/32 [==============================] - 0s 666us/step - loss: 0.7242\n",
      "Epoch 87/300\n",
      "32/32 [==============================] - 0s 623us/step - loss: 0.5534\n",
      "Epoch 88/300\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.4088\n",
      "Epoch 89/300\n",
      "32/32 [==============================] - 0s 713us/step - loss: 0.2909\n",
      "Epoch 90/300\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.1983\n",
      "Epoch 91/300\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1282\n",
      "Epoch 92/300\n",
      "32/32 [==============================] - 0s 883us/step - loss: 0.0799\n",
      "Epoch 93/300\n",
      "32/32 [==============================] - 0s 802us/step - loss: 0.0508\n",
      "Epoch 94/300\n",
      "32/32 [==============================] - 0s 795us/step - loss: 0.0374\n",
      "Epoch 95/300\n",
      "32/32 [==============================] - 0s 646us/step - loss: 0.0313\n",
      "Epoch 96/300\n",
      "32/32 [==============================] - 0s 748us/step - loss: 0.0272\n",
      "Epoch 97/300\n",
      "32/32 [==============================] - 0s 622us/step - loss: 0.0233\n",
      "Epoch 98/300\n",
      "32/32 [==============================] - 0s 656us/step - loss: 0.0197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/300\n",
      "32/32 [==============================] - 0s 728us/step - loss: 0.0165\n",
      "Epoch 100/300\n",
      "32/32 [==============================] - 0s 685us/step - loss: 0.0137\n",
      "Epoch 101/300\n",
      "32/32 [==============================] - 0s 616us/step - loss: 0.0111\n",
      "Epoch 102/300\n",
      "32/32 [==============================] - 0s 742us/step - loss: 0.0087\n",
      "Epoch 103/300\n",
      "32/32 [==============================] - 0s 605us/step - loss: 0.0068\n",
      "Epoch 104/300\n",
      "32/32 [==============================] - 0s 614us/step - loss: 0.0050\n",
      "Epoch 105/300\n",
      "32/32 [==============================] - 0s 646us/step - loss: 0.0036\n",
      "Epoch 106/300\n",
      "32/32 [==============================] - 0s 607us/step - loss: 0.0024\n",
      "Epoch 107/300\n",
      "32/32 [==============================] - 0s 576us/step - loss: 0.0014\n",
      "Epoch 108/300\n",
      "32/32 [==============================] - 0s 655us/step - loss: 7.4073e-04\n",
      "Epoch 109/300\n",
      "32/32 [==============================] - 0s 598us/step - loss: 3.2350e-04\n",
      "Epoch 110/300\n",
      "32/32 [==============================] - 0s 578us/step - loss: 1.0823e-04\n",
      "Epoch 111/300\n",
      "32/32 [==============================] - 0s 625us/step - loss: 3.9624e-05\n",
      "Epoch 112/300\n",
      "32/32 [==============================] - 0s 640us/step - loss: 2.5376e-05\n",
      "Epoch 113/300\n",
      "32/32 [==============================] - 0s 602us/step - loss: 3.0340e-05\n",
      "Epoch 114/300\n",
      "32/32 [==============================] - 0s 635us/step - loss: 3.0464e-05\n",
      "Epoch 115/300\n",
      "32/32 [==============================] - 0s 615us/step - loss: 2.8088e-05\n",
      "Epoch 116/300\n",
      "32/32 [==============================] - 0s 631us/step - loss: 2.3904e-05\n",
      "Epoch 117/300\n",
      "32/32 [==============================] - 0s 628us/step - loss: 2.2518e-05\n",
      "Epoch 118/300\n",
      "32/32 [==============================] - 0s 635us/step - loss: 2.7592e-05\n",
      "Epoch 119/300\n",
      "32/32 [==============================] - 0s 596us/step - loss: 3.1014e-05\n",
      "Epoch 120/300\n",
      "32/32 [==============================] - 0s 581us/step - loss: 2.6527e-05\n",
      "Epoch 121/300\n",
      "32/32 [==============================] - 0s 613us/step - loss: 2.8067e-05\n",
      "Epoch 122/300\n",
      "32/32 [==============================] - 0s 621us/step - loss: 2.6759e-05\n",
      "Epoch 123/300\n",
      "32/32 [==============================] - 0s 633us/step - loss: 3.0905e-05\n",
      "Epoch 124/300\n",
      "32/32 [==============================] - 0s 618us/step - loss: 2.6909e-05\n",
      "Epoch 125/300\n",
      "32/32 [==============================] - 0s 604us/step - loss: 2.3035e-05\n",
      "Epoch 126/300\n",
      "32/32 [==============================] - 0s 638us/step - loss: 2.5959e-05\n",
      "Epoch 127/300\n",
      "32/32 [==============================] - 0s 637us/step - loss: 2.5578e-05\n",
      "Epoch 128/300\n",
      "32/32 [==============================] - 0s 610us/step - loss: 2.7172e-05\n",
      "Epoch 129/300\n",
      "32/32 [==============================] - 0s 620us/step - loss: 2.6337e-05\n",
      "Epoch 130/300\n",
      "32/32 [==============================] - 0s 737us/step - loss: 3.1728e-05\n",
      "Epoch 131/300\n",
      "32/32 [==============================] - 0s 624us/step - loss: 2.6252e-05\n",
      "Epoch 132/300\n",
      "32/32 [==============================] - 0s 616us/step - loss: 2.5409e-05\n",
      "Epoch 133/300\n",
      "32/32 [==============================] - 0s 639us/step - loss: 2.9593e-05\n",
      "Epoch 134/300\n",
      "32/32 [==============================] - 0s 633us/step - loss: 2.6023e-05\n",
      "Epoch 135/300\n",
      "32/32 [==============================] - 0s 638us/step - loss: 2.5562e-05\n",
      "Epoch 136/300\n",
      "32/32 [==============================] - 0s 643us/step - loss: 3.1087e-05\n",
      "Epoch 137/300\n",
      "32/32 [==============================] - 0s 639us/step - loss: 2.5416e-05\n",
      "Epoch 138/300\n",
      "32/32 [==============================] - 0s 616us/step - loss: 2.9429e-05\n",
      "Epoch 139/300\n",
      "32/32 [==============================] - 0s 649us/step - loss: 2.5094e-05\n",
      "Epoch 140/300\n",
      "32/32 [==============================] - 0s 605us/step - loss: 2.8381e-05\n",
      "Epoch 141/300\n",
      "32/32 [==============================] - 0s 629us/step - loss: 2.4256e-05\n",
      "Epoch 142/300\n",
      "32/32 [==============================] - 0s 636us/step - loss: 2.9864e-05\n",
      "Epoch 143/300\n",
      "32/32 [==============================] - 0s 622us/step - loss: 2.7106e-05\n",
      "Epoch 144/300\n",
      "32/32 [==============================] - 0s 606us/step - loss: 2.8875e-05\n",
      "Epoch 145/300\n",
      "32/32 [==============================] - 0s 643us/step - loss: 2.3208e-05\n",
      "Epoch 146/300\n",
      "32/32 [==============================] - 0s 636us/step - loss: 3.0628e-05\n",
      "Epoch 147/300\n",
      "32/32 [==============================] - 0s 572us/step - loss: 2.5972e-05\n",
      "Epoch 148/300\n",
      "32/32 [==============================] - 0s 693us/step - loss: 2.8859e-05\n",
      "Epoch 149/300\n",
      "32/32 [==============================] - 0s 595us/step - loss: 2.3545e-05\n",
      "Epoch 150/300\n",
      "32/32 [==============================] - 0s 585us/step - loss: 2.5482e-05\n",
      "Epoch 151/300\n",
      "32/32 [==============================] - 0s 714us/step - loss: 2.5398e-05\n",
      "Epoch 152/300\n",
      "32/32 [==============================] - 0s 596us/step - loss: 2.6528e-05\n",
      "Epoch 153/300\n",
      "32/32 [==============================] - 0s 572us/step - loss: 3.0786e-05\n",
      "Epoch 154/300\n",
      "32/32 [==============================] - 0s 640us/step - loss: 2.9811e-05\n",
      "Epoch 155/300\n",
      "32/32 [==============================] - 0s 609us/step - loss: 2.6064e-05\n",
      "Epoch 156/300\n",
      "32/32 [==============================] - 0s 578us/step - loss: 2.7889e-05\n",
      "Epoch 157/300\n",
      "32/32 [==============================] - 0s 609us/step - loss: 2.8989e-05\n",
      "Epoch 158/300\n",
      "32/32 [==============================] - 0s 651us/step - loss: 2.3259e-05\n",
      "Epoch 159/300\n",
      "32/32 [==============================] - 0s 594us/step - loss: 3.0106e-05\n",
      "Epoch 160/300\n",
      "32/32 [==============================] - 0s 619us/step - loss: 3.0202e-05\n",
      "Epoch 161/300\n",
      "32/32 [==============================] - 0s 643us/step - loss: 2.5057e-05\n",
      "Epoch 162/300\n",
      "32/32 [==============================] - 0s 629us/step - loss: 2.4331e-05\n",
      "Epoch 163/300\n",
      "32/32 [==============================] - 0s 610us/step - loss: 2.7187e-05\n",
      "Epoch 164/300\n",
      "32/32 [==============================] - 0s 608us/step - loss: 2.6626e-05\n",
      "Epoch 165/300\n",
      "32/32 [==============================] - 0s 614us/step - loss: 2.9510e-05\n",
      "Epoch 166/300\n",
      "32/32 [==============================] - 0s 596us/step - loss: 3.0593e-05\n",
      "Epoch 167/300\n",
      "32/32 [==============================] - 0s 629us/step - loss: 3.1799e-05\n",
      "Epoch 168/300\n",
      "32/32 [==============================] - 0s 622us/step - loss: 2.0320e-05\n",
      "Epoch 169/300\n",
      "32/32 [==============================] - 0s 648us/step - loss: 2.7745e-05\n",
      "Epoch 170/300\n",
      "32/32 [==============================] - 0s 869us/step - loss: 2.7203e-05\n",
      "Epoch 171/300\n",
      "32/32 [==============================] - 0s 811us/step - loss: 2.6135e-05\n",
      "Epoch 172/300\n",
      "32/32 [==============================] - 0s 761us/step - loss: 3.1238e-05\n",
      "Epoch 173/300\n",
      "32/32 [==============================] - 0s 809us/step - loss: 2.6624e-05\n",
      "Epoch 174/300\n",
      "32/32 [==============================] - 0s 716us/step - loss: 2.4044e-05\n",
      "Epoch 175/300\n",
      "32/32 [==============================] - 0s 980us/step - loss: 3.0262e-05\n",
      "Epoch 176/300\n",
      "32/32 [==============================] - 0s 764us/step - loss: 2.9681e-05\n",
      "Epoch 177/300\n",
      "32/32 [==============================] - 0s 875us/step - loss: 2.9038e-05\n",
      "Epoch 178/300\n",
      "32/32 [==============================] - 0s 694us/step - loss: 2.5109e-05\n",
      "Epoch 179/300\n",
      "32/32 [==============================] - 0s 751us/step - loss: 2.9488e-05\n",
      "Epoch 180/300\n",
      "32/32 [==============================] - 0s 637us/step - loss: 2.3549e-05\n",
      "Epoch 181/300\n",
      "32/32 [==============================] - 0s 642us/step - loss: 2.5076e-05\n",
      "Epoch 182/300\n",
      "32/32 [==============================] - 0s 635us/step - loss: 3.0338e-05\n",
      "Epoch 183/300\n",
      "32/32 [==============================] - 0s 728us/step - loss: 2.8479e-05\n",
      "Epoch 184/300\n",
      "32/32 [==============================] - 0s 592us/step - loss: 2.3555e-05\n",
      "Epoch 185/300\n",
      "32/32 [==============================] - 0s 713us/step - loss: 2.9385e-05\n",
      "Epoch 186/300\n",
      "32/32 [==============================] - 0s 638us/step - loss: 2.9175e-05\n",
      "Epoch 187/300\n",
      "32/32 [==============================] - 0s 596us/step - loss: 2.6531e-05\n",
      "Epoch 188/300\n",
      "32/32 [==============================] - 0s 666us/step - loss: 2.9614e-05\n",
      "Epoch 189/300\n",
      "32/32 [==============================] - 0s 794us/step - loss: 2.5688e-05\n",
      "Epoch 190/300\n",
      "32/32 [==============================] - 0s 715us/step - loss: 2.6998e-05\n",
      "Epoch 191/300\n",
      "32/32 [==============================] - 0s 836us/step - loss: 2.7165e-05\n",
      "Epoch 192/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 720us/step - loss: 2.4410e-05\n",
      "Epoch 193/300\n",
      "32/32 [==============================] - 0s 720us/step - loss: 2.8806e-05\n",
      "Epoch 194/300\n",
      "32/32 [==============================] - 0s 833us/step - loss: 2.7824e-05\n",
      "Epoch 195/300\n",
      "32/32 [==============================] - 0s 638us/step - loss: 2.7521e-05\n",
      "Epoch 196/300\n",
      "32/32 [==============================] - 0s 814us/step - loss: 2.8102e-05\n",
      "Epoch 197/300\n",
      "32/32 [==============================] - 0s 656us/step - loss: 3.1237e-05\n",
      "Epoch 198/300\n",
      "32/32 [==============================] - 0s 723us/step - loss: 2.0753e-05\n",
      "Epoch 199/300\n",
      "32/32 [==============================] - 0s 710us/step - loss: 2.7154e-05\n",
      "Epoch 200/300\n",
      "32/32 [==============================] - 0s 681us/step - loss: 2.8029e-05\n",
      "Epoch 201/300\n",
      "32/32 [==============================] - 0s 719us/step - loss: 3.1191e-05\n",
      "Epoch 202/300\n",
      "32/32 [==============================] - 0s 766us/step - loss: 2.4711e-05\n",
      "Epoch 203/300\n",
      "32/32 [==============================] - 0s 685us/step - loss: 2.7172e-05\n",
      "Epoch 204/300\n",
      "32/32 [==============================] - 0s 856us/step - loss: 3.1244e-05\n",
      "Epoch 205/300\n",
      "32/32 [==============================] - 0s 623us/step - loss: 2.5835e-05\n",
      "Epoch 206/300\n",
      "32/32 [==============================] - 0s 615us/step - loss: 2.6630e-05\n",
      "Epoch 207/300\n",
      "32/32 [==============================] - 0s 680us/step - loss: 2.2449e-05\n",
      "Epoch 208/300\n",
      "32/32 [==============================] - 0s 596us/step - loss: 3.2855e-05\n",
      "Epoch 209/300\n",
      "32/32 [==============================] - 0s 590us/step - loss: 2.7188e-05\n",
      "Epoch 210/300\n",
      "32/32 [==============================] - 0s 725us/step - loss: 2.2643e-05\n",
      "Epoch 211/300\n",
      "32/32 [==============================] - 0s 625us/step - loss: 2.5711e-05\n",
      "Epoch 212/300\n",
      "32/32 [==============================] - 0s 598us/step - loss: 2.2839e-05\n",
      "Epoch 213/300\n",
      "32/32 [==============================] - 0s 668us/step - loss: 3.0024e-05\n",
      "Epoch 214/300\n",
      "32/32 [==============================] - 0s 614us/step - loss: 2.8795e-05\n",
      "Epoch 215/300\n",
      "32/32 [==============================] - 0s 597us/step - loss: 2.9752e-05\n",
      "Epoch 216/300\n",
      "32/32 [==============================] - 0s 727us/step - loss: 2.6074e-05\n",
      "Epoch 217/300\n",
      "32/32 [==============================] - 0s 762us/step - loss: 2.7214e-05\n",
      "Epoch 218/300\n",
      "32/32 [==============================] - 0s 878us/step - loss: 2.8958e-05\n",
      "Epoch 219/300\n",
      "32/32 [==============================] - 0s 734us/step - loss: 2.6830e-05\n",
      "Epoch 220/300\n",
      "32/32 [==============================] - 0s 723us/step - loss: 2.9408e-05\n",
      "Epoch 221/300\n",
      "32/32 [==============================] - 0s 749us/step - loss: 2.4542e-05\n",
      "Epoch 222/300\n",
      "32/32 [==============================] - 0s 739us/step - loss: 3.0493e-05\n",
      "Epoch 223/300\n",
      "32/32 [==============================] - 0s 725us/step - loss: 2.5933e-05\n",
      "Epoch 224/300\n",
      "32/32 [==============================] - 0s 856us/step - loss: 2.4475e-05\n",
      "Epoch 225/300\n",
      "32/32 [==============================] - 0s 731us/step - loss: 2.9368e-05\n",
      "Epoch 226/300\n",
      "32/32 [==============================] - 0s 893us/step - loss: 3.1948e-05\n",
      "Epoch 227/300\n",
      "32/32 [==============================] - 0s 698us/step - loss: 2.5965e-05\n",
      "Epoch 228/300\n",
      "32/32 [==============================] - 0s 780us/step - loss: 2.7160e-05\n",
      "Epoch 229/300\n",
      "32/32 [==============================] - 0s 728us/step - loss: 2.7684e-05\n",
      "Epoch 230/300\n",
      "32/32 [==============================] - 0s 733us/step - loss: 2.8221e-05\n",
      "Epoch 231/300\n",
      "32/32 [==============================] - 0s 833us/step - loss: 3.0966e-05\n",
      "Epoch 232/300\n",
      "32/32 [==============================] - 0s 707us/step - loss: 2.3624e-05\n",
      "Epoch 233/300\n",
      "32/32 [==============================] - 0s 716us/step - loss: 3.0552e-05\n",
      "Epoch 234/300\n",
      "32/32 [==============================] - 0s 772us/step - loss: 2.3732e-05\n",
      "Epoch 235/300\n",
      "32/32 [==============================] - 0s 720us/step - loss: 2.2775e-05\n",
      "Epoch 236/300\n",
      "32/32 [==============================] - 0s 665us/step - loss: 3.2360e-05\n",
      "Epoch 237/300\n",
      "32/32 [==============================] - 0s 664us/step - loss: 2.7752e-05\n",
      "Epoch 238/300\n",
      "32/32 [==============================] - 0s 710us/step - loss: 2.5581e-05\n",
      "Epoch 239/300\n",
      "32/32 [==============================] - 0s 830us/step - loss: 2.5085e-05\n",
      "Epoch 240/300\n",
      "32/32 [==============================] - 0s 728us/step - loss: 2.6499e-05\n",
      "Epoch 241/300\n",
      "32/32 [==============================] - 0s 698us/step - loss: 2.9098e-05\n",
      "Epoch 242/300\n",
      "32/32 [==============================] - 0s 795us/step - loss: 2.9865e-05\n",
      "Epoch 243/300\n",
      "32/32 [==============================] - 0s 622us/step - loss: 3.0854e-05\n",
      "Epoch 244/300\n",
      "32/32 [==============================] - 0s 641us/step - loss: 1.8164e-05\n",
      "Epoch 245/300\n",
      "32/32 [==============================] - 0s 750us/step - loss: 2.8243e-05\n",
      "Epoch 246/300\n",
      "32/32 [==============================] - 0s 745us/step - loss: 3.1564e-05\n",
      "Epoch 247/300\n",
      "32/32 [==============================] - 0s 811us/step - loss: 2.7078e-05\n",
      "Epoch 248/300\n",
      "32/32 [==============================] - 0s 857us/step - loss: 2.3779e-05\n",
      "Epoch 249/300\n",
      "32/32 [==============================] - 0s 818us/step - loss: 2.7443e-05\n",
      "Epoch 250/300\n",
      "32/32 [==============================] - 0s 658us/step - loss: 2.8068e-05\n",
      "Epoch 251/300\n",
      "32/32 [==============================] - 0s 604us/step - loss: 2.8204e-05\n",
      "Epoch 252/300\n",
      "32/32 [==============================] - 0s 647us/step - loss: 2.5454e-05\n",
      "Epoch 253/300\n",
      "32/32 [==============================] - 0s 618us/step - loss: 2.9104e-05\n",
      "Epoch 254/300\n",
      "32/32 [==============================] - 0s 653us/step - loss: 3.0760e-05\n",
      "Epoch 255/300\n",
      "32/32 [==============================] - 0s 768us/step - loss: 2.8913e-05\n",
      "Epoch 256/300\n",
      "32/32 [==============================] - 0s 682us/step - loss: 2.6700e-05\n",
      "Epoch 257/300\n",
      "32/32 [==============================] - 0s 608us/step - loss: 3.0330e-05\n",
      "Epoch 258/300\n",
      "32/32 [==============================] - 0s 688us/step - loss: 2.3803e-05\n",
      "Epoch 259/300\n",
      "32/32 [==============================] - 0s 780us/step - loss: 2.7201e-05\n",
      "Epoch 260/300\n",
      "32/32 [==============================] - 0s 797us/step - loss: 2.9967e-05\n",
      "Epoch 261/300\n",
      "32/32 [==============================] - 0s 841us/step - loss: 2.6534e-05\n",
      "Epoch 262/300\n",
      "32/32 [==============================] - 0s 781us/step - loss: 2.9633e-05\n",
      "Epoch 263/300\n",
      "32/32 [==============================] - 0s 754us/step - loss: 2.5309e-05\n",
      "Epoch 264/300\n",
      "32/32 [==============================] - 0s 786us/step - loss: 2.8499e-05\n",
      "Epoch 265/300\n",
      "32/32 [==============================] - 0s 699us/step - loss: 3.1981e-05\n",
      "Epoch 266/300\n",
      "32/32 [==============================] - 0s 863us/step - loss: 3.0267e-05\n",
      "Epoch 267/300\n",
      "32/32 [==============================] - 0s 719us/step - loss: 2.2913e-05\n",
      "Epoch 268/300\n",
      "32/32 [==============================] - 0s 727us/step - loss: 2.6688e-05\n",
      "Epoch 269/300\n",
      "32/32 [==============================] - 0s 794us/step - loss: 2.6375e-05\n",
      "Epoch 270/300\n",
      "32/32 [==============================] - 0s 794us/step - loss: 2.7663e-05\n",
      "Epoch 271/300\n",
      "32/32 [==============================] - 0s 991us/step - loss: 2.7352e-05\n",
      "Epoch 272/300\n",
      "32/32 [==============================] - 0s 712us/step - loss: 2.9430e-05\n",
      "Epoch 273/300\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.1338e-05\n",
      "Epoch 274/300\n",
      "32/32 [==============================] - 0s 792us/step - loss: 2.5620e-05\n",
      "Epoch 275/300\n",
      "32/32 [==============================] - 0s 728us/step - loss: 2.7478e-05\n",
      "Epoch 276/300\n",
      "32/32 [==============================] - 0s 682us/step - loss: 2.2606e-05\n",
      "Epoch 277/300\n",
      "32/32 [==============================] - 0s 840us/step - loss: 2.7247e-05\n",
      "Epoch 278/300\n",
      "32/32 [==============================] - 0s 716us/step - loss: 3.0010e-05\n",
      "Epoch 279/300\n",
      "32/32 [==============================] - 0s 697us/step - loss: 2.6322e-05\n",
      "Epoch 280/300\n",
      "32/32 [==============================] - 0s 731us/step - loss: 2.7233e-05\n",
      "Epoch 281/300\n",
      "32/32 [==============================] - 0s 724us/step - loss: 2.3668e-05\n",
      "Epoch 282/300\n",
      "32/32 [==============================] - 0s 877us/step - loss: 3.1558e-05\n",
      "Epoch 283/300\n",
      "32/32 [==============================] - 0s 613us/step - loss: 2.9051e-05\n",
      "Epoch 284/300\n",
      "32/32 [==============================] - 0s 677us/step - loss: 2.5559e-05\n",
      "Epoch 285/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 760us/step - loss: 2.8193e-05\n",
      "Epoch 286/300\n",
      "32/32 [==============================] - 0s 662us/step - loss: 2.6698e-05\n",
      "Epoch 287/300\n",
      "32/32 [==============================] - 0s 705us/step - loss: 3.2007e-05\n",
      "Epoch 288/300\n",
      "32/32 [==============================] - 0s 758us/step - loss: 2.9326e-05\n",
      "Epoch 289/300\n",
      "32/32 [==============================] - 0s 693us/step - loss: 1.7677e-05\n",
      "Epoch 290/300\n",
      "32/32 [==============================] - 0s 706us/step - loss: 3.2090e-05\n",
      "Epoch 291/300\n",
      "32/32 [==============================] - 0s 706us/step - loss: 2.8643e-05\n",
      "Epoch 292/300\n",
      "32/32 [==============================] - 0s 668us/step - loss: 2.6105e-05\n",
      "Epoch 293/300\n",
      "32/32 [==============================] - 0s 726us/step - loss: 3.2065e-05\n",
      "Epoch 294/300\n",
      "32/32 [==============================] - 0s 710us/step - loss: 2.7549e-05\n",
      "Epoch 295/300\n",
      "32/32 [==============================] - 0s 654us/step - loss: 2.7700e-05\n",
      "Epoch 296/300\n",
      "32/32 [==============================] - 0s 716us/step - loss: 2.6773e-05\n",
      "Epoch 297/300\n",
      "32/32 [==============================] - 0s 682us/step - loss: 2.8369e-05\n",
      "Epoch 298/300\n",
      "32/32 [==============================] - 0s 824us/step - loss: 2.0936e-05\n",
      "Epoch 299/300\n",
      "32/32 [==============================] - 0s 686us/step - loss: 3.2916e-05\n",
      "Epoch 300/300\n",
      "32/32 [==============================] - 0s 713us/step - loss: 2.7229e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x187fc6850>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(inputs, f_vec, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef05eb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40e45234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       "array([[ 9.000688 ],\n",
       "       [13.001579 ],\n",
       "       [ 5.0041504],\n",
       "       [-0.9993645],\n",
       "       [-0.9993645],\n",
       "       [-0.9979135],\n",
       "       [16.003336 ],\n",
       "       [11.00186  ],\n",
       "       [ 1.0032586],\n",
       "       [ 3.0015266]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3f02bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_diff(preds, ys, m):\n",
    "    preds = preds.numpy()\n",
    "    preds = [int(np.round(x)) for x in preds[:m]]\n",
    "    print(preds)\n",
    "    print(list(ys[:m]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66173cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 13, 5, -1, -1, -1, 16, 11, 1, 3]\n",
      "[9, 13, 5, -1, -1, -1, 16, 11, 1, 3]\n"
     ]
    }
   ],
   "source": [
    "show_diff(preds, f_vec, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61fed53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense/kernel:0' shape=(2, 1) dtype=float32, numpy=\n",
       " array([[ 3.000306 ],\n",
       "        [-1.9997202]], dtype=float32)>,\n",
       " <tf.Variable 'dense/bias:0' shape=(1,) dtype=float32, numpy=array([-0.00022998], dtype=float32)>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.trainable_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c0c3c4",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab2a06f",
   "metadata": {},
   "source": [
    "f(x) = x^2 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0dc70489",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.random.randint(10, size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b10b32a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 1, 3, 7, 2, 8, 5, 7, 4])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1d95330c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17, 17,  2, 10, 50,  5, 65, 26, 50, 17])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys = np.array([x**2 + 1 for x in xs])\n",
    "ys[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8ea84028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 4],\n",
       "       [4, 4],\n",
       "       [1, 1],\n",
       "       [3, 3],\n",
       "       [7, 7],\n",
       "       [2, 2],\n",
       "       [8, 8],\n",
       "       [5, 5],\n",
       "       [7, 7],\n",
       "       [4, 4]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_inputs = np.stack([xs, xs], axis=1)\n",
    "new_inputs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7d454f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = keras.Sequential([\n",
    "    keras.layers.Dense(4, activation='tanh', input_dim=2),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8dfdc32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(\n",
    "    loss='mean_squared_error'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6e5158f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "32/32 [==============================] - 0s 737us/step - loss: 10.3671\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 0s 688us/step - loss: 10.1857\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 0s 825us/step - loss: 10.0040\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 0s 698us/step - loss: 9.8434\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 0s 730us/step - loss: 9.6761\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 0s 919us/step - loss: 9.5264\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 0s 818us/step - loss: 9.3293\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 0s 767us/step - loss: 9.1960\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 0s 704us/step - loss: 9.0245\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 0s 725us/step - loss: 8.8677\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 0s 717us/step - loss: 8.7330\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 0s 778us/step - loss: 8.5865\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 0s 892us/step - loss: 8.4275\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 0s 782us/step - loss: 8.2810\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 0s 898us/step - loss: 8.1659\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 0s 770us/step - loss: 8.0168\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 0s 804us/step - loss: 7.9012\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 0s 715us/step - loss: 7.7451\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 0s 657us/step - loss: 7.6340\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 0s 748us/step - loss: 7.4731\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 0s 684us/step - loss: 7.3354\n",
      "Epoch 22/500\n",
      "32/32 [==============================] - 0s 724us/step - loss: 7.1994\n",
      "Epoch 23/500\n",
      "32/32 [==============================] - 0s 760us/step - loss: 7.0780\n",
      "Epoch 24/500\n",
      "32/32 [==============================] - 0s 676us/step - loss: 6.9766\n",
      "Epoch 25/500\n",
      "32/32 [==============================] - 0s 715us/step - loss: 6.8332\n",
      "Epoch 26/500\n",
      "32/32 [==============================] - 0s 722us/step - loss: 6.6941\n",
      "Epoch 27/500\n",
      "32/32 [==============================] - 0s 717us/step - loss: 6.5746\n",
      "Epoch 28/500\n",
      "32/32 [==============================] - 0s 921us/step - loss: 6.4694\n",
      "Epoch 29/500\n",
      "32/32 [==============================] - 0s 786us/step - loss: 6.3408\n",
      "Epoch 30/500\n",
      "32/32 [==============================] - 0s 759us/step - loss: 6.2236\n",
      "Epoch 31/500\n",
      "32/32 [==============================] - 0s 751us/step - loss: 6.1064\n",
      "Epoch 32/500\n",
      "32/32 [==============================] - 0s 658us/step - loss: 6.0360\n",
      "Epoch 33/500\n",
      "32/32 [==============================] - 0s 738us/step - loss: 5.8869\n",
      "Epoch 34/500\n",
      "32/32 [==============================] - 0s 693us/step - loss: 5.7804\n",
      "Epoch 35/500\n",
      "32/32 [==============================] - 0s 697us/step - loss: 5.6846\n",
      "Epoch 36/500\n",
      "32/32 [==============================] - 0s 768us/step - loss: 5.5972\n",
      "Epoch 37/500\n",
      "32/32 [==============================] - 0s 793us/step - loss: 5.5100\n",
      "Epoch 38/500\n",
      "32/32 [==============================] - 0s 714us/step - loss: 5.3964\n",
      "Epoch 39/500\n",
      "32/32 [==============================] - 0s 697us/step - loss: 5.3161\n",
      "Epoch 40/500\n",
      "32/32 [==============================] - 0s 677us/step - loss: 5.1858\n",
      "Epoch 41/500\n",
      "32/32 [==============================] - 0s 700us/step - loss: 5.1094\n",
      "Epoch 42/500\n",
      "32/32 [==============================] - 0s 766us/step - loss: 5.0179\n",
      "Epoch 43/500\n",
      "32/32 [==============================] - 0s 729us/step - loss: 4.9347\n",
      "Epoch 44/500\n",
      "32/32 [==============================] - 0s 769us/step - loss: 4.8357\n",
      "Epoch 45/500\n",
      "32/32 [==============================] - 0s 755us/step - loss: 4.7602\n",
      "Epoch 46/500\n",
      "32/32 [==============================] - 0s 694us/step - loss: 4.6472\n",
      "Epoch 47/500\n",
      "32/32 [==============================] - 0s 798us/step - loss: 4.5660\n",
      "Epoch 48/500\n",
      "32/32 [==============================] - 0s 722us/step - loss: 4.4581\n",
      "Epoch 49/500\n",
      "32/32 [==============================] - 0s 813us/step - loss: 4.3972\n",
      "Epoch 50/500\n",
      "32/32 [==============================] - 0s 721us/step - loss: 4.3052\n",
      "Epoch 51/500\n",
      "32/32 [==============================] - 0s 743us/step - loss: 4.2335\n",
      "Epoch 52/500\n",
      "32/32 [==============================] - 0s 787us/step - loss: 4.1518\n",
      "Epoch 53/500\n",
      "32/32 [==============================] - 0s 730us/step - loss: 4.0800\n",
      "Epoch 54/500\n",
      "32/32 [==============================] - 0s 762us/step - loss: 3.9860\n",
      "Epoch 55/500\n",
      "32/32 [==============================] - 0s 720us/step - loss: 3.9342\n",
      "Epoch 56/500\n",
      "32/32 [==============================] - 0s 810us/step - loss: 3.8530\n",
      "Epoch 57/500\n",
      "32/32 [==============================] - 0s 773us/step - loss: 3.7866\n",
      "Epoch 58/500\n",
      "32/32 [==============================] - 0s 667us/step - loss: 3.7058\n",
      "Epoch 59/500\n",
      "32/32 [==============================] - 0s 702us/step - loss: 3.6199\n",
      "Epoch 60/500\n",
      "32/32 [==============================] - 0s 697us/step - loss: 3.5767\n",
      "Epoch 61/500\n",
      "32/32 [==============================] - 0s 653us/step - loss: 3.5092\n",
      "Epoch 62/500\n",
      "32/32 [==============================] - 0s 738us/step - loss: 3.4284\n",
      "Epoch 63/500\n",
      "32/32 [==============================] - 0s 714us/step - loss: 3.3784\n",
      "Epoch 64/500\n",
      "32/32 [==============================] - 0s 646us/step - loss: 3.3272\n",
      "Epoch 65/500\n",
      "32/32 [==============================] - 0s 598us/step - loss: 3.2550\n",
      "Epoch 66/500\n",
      "32/32 [==============================] - 0s 625us/step - loss: 3.2088\n",
      "Epoch 67/500\n",
      "32/32 [==============================] - 0s 597us/step - loss: 3.1546\n",
      "Epoch 68/500\n",
      "32/32 [==============================] - 0s 753us/step - loss: 3.0824\n",
      "Epoch 69/500\n",
      "32/32 [==============================] - 0s 701us/step - loss: 3.0282\n",
      "Epoch 70/500\n",
      "32/32 [==============================] - 0s 673us/step - loss: 2.9651\n",
      "Epoch 71/500\n",
      "32/32 [==============================] - 0s 712us/step - loss: 2.9570\n",
      "Epoch 72/500\n",
      "32/32 [==============================] - 0s 692us/step - loss: 2.8448\n",
      "Epoch 73/500\n",
      "32/32 [==============================] - 0s 666us/step - loss: 2.8251\n",
      "Epoch 74/500\n",
      "32/32 [==============================] - 0s 692us/step - loss: 2.7608\n",
      "Epoch 75/500\n",
      "32/32 [==============================] - 0s 773us/step - loss: 2.7060\n",
      "Epoch 76/500\n",
      "32/32 [==============================] - 0s 681us/step - loss: 2.6549\n",
      "Epoch 77/500\n",
      "32/32 [==============================] - 0s 782us/step - loss: 2.6177\n",
      "Epoch 78/500\n",
      "32/32 [==============================] - 0s 693us/step - loss: 2.5546\n",
      "Epoch 79/500\n",
      "32/32 [==============================] - 0s 757us/step - loss: 2.4957\n",
      "Epoch 80/500\n",
      "32/32 [==============================] - 0s 673us/step - loss: 2.4832\n",
      "Epoch 81/500\n",
      "32/32 [==============================] - 0s 693us/step - loss: 2.4268\n",
      "Epoch 82/500\n",
      "32/32 [==============================] - 0s 685us/step - loss: 2.3860\n",
      "Epoch 83/500\n",
      "32/32 [==============================] - 0s 673us/step - loss: 2.3104\n",
      "Epoch 84/500\n",
      "32/32 [==============================] - 0s 669us/step - loss: 2.3102\n",
      "Epoch 85/500\n",
      "32/32 [==============================] - 0s 735us/step - loss: 2.2397\n",
      "Epoch 86/500\n",
      "32/32 [==============================] - 0s 670us/step - loss: 2.2173\n",
      "Epoch 87/500\n",
      "32/32 [==============================] - 0s 672us/step - loss: 2.1793\n",
      "Epoch 88/500\n",
      "32/32 [==============================] - 0s 749us/step - loss: 2.1211\n",
      "Epoch 89/500\n",
      "32/32 [==============================] - 0s 658us/step - loss: 2.0990\n",
      "Epoch 90/500\n",
      "32/32 [==============================] - 0s 728us/step - loss: 2.0725\n",
      "Epoch 91/500\n",
      "32/32 [==============================] - 0s 679us/step - loss: 2.0046\n",
      "Epoch 92/500\n",
      "32/32 [==============================] - 0s 664us/step - loss: 1.9728\n",
      "Epoch 93/500\n",
      "32/32 [==============================] - 0s 721us/step - loss: 1.9753\n",
      "Epoch 94/500\n",
      "32/32 [==============================] - 0s 682us/step - loss: 1.9028\n",
      "Epoch 95/500\n",
      "32/32 [==============================] - 0s 830us/step - loss: 1.8849\n",
      "Epoch 96/500\n",
      "32/32 [==============================] - 0s 879us/step - loss: 1.8449\n",
      "Epoch 97/500\n",
      "32/32 [==============================] - 0s 815us/step - loss: 1.8134\n",
      "Epoch 98/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.7688\n",
      "Epoch 99/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 778us/step - loss: 1.7544\n",
      "Epoch 100/500\n",
      "32/32 [==============================] - 0s 811us/step - loss: 1.7346\n",
      "Epoch 101/500\n",
      "32/32 [==============================] - 0s 752us/step - loss: 1.6884\n",
      "Epoch 102/500\n",
      "32/32 [==============================] - 0s 715us/step - loss: 1.6404\n",
      "Epoch 103/500\n",
      "32/32 [==============================] - 0s 692us/step - loss: 1.6168\n",
      "Epoch 104/500\n",
      "32/32 [==============================] - 0s 669us/step - loss: 1.5979\n",
      "Epoch 105/500\n",
      "32/32 [==============================] - 0s 655us/step - loss: 1.5573\n",
      "Epoch 106/500\n",
      "32/32 [==============================] - 0s 667us/step - loss: 1.5397\n",
      "Epoch 107/500\n",
      "32/32 [==============================] - 0s 668us/step - loss: 1.5293\n",
      "Epoch 108/500\n",
      "32/32 [==============================] - 0s 653us/step - loss: 1.4615\n",
      "Epoch 109/500\n",
      "32/32 [==============================] - 0s 693us/step - loss: 1.4782\n",
      "Epoch 110/500\n",
      "32/32 [==============================] - 0s 649us/step - loss: 1.4168\n",
      "Epoch 111/500\n",
      "32/32 [==============================] - 0s 662us/step - loss: 1.4250\n",
      "Epoch 112/500\n",
      "32/32 [==============================] - 0s 699us/step - loss: 1.3893\n",
      "Epoch 113/500\n",
      "32/32 [==============================] - 0s 656us/step - loss: 1.3472\n",
      "Epoch 114/500\n",
      "32/32 [==============================] - 0s 706us/step - loss: 1.3302\n",
      "Epoch 115/500\n",
      "32/32 [==============================] - 0s 669us/step - loss: 1.3078\n",
      "Epoch 116/500\n",
      "32/32 [==============================] - 0s 690us/step - loss: 1.3076\n",
      "Epoch 117/500\n",
      "32/32 [==============================] - 0s 771us/step - loss: 1.2622\n",
      "Epoch 118/500\n",
      "32/32 [==============================] - 0s 796us/step - loss: 1.2528\n",
      "Epoch 119/500\n",
      "32/32 [==============================] - 0s 727us/step - loss: 1.2207\n",
      "Epoch 120/500\n",
      "32/32 [==============================] - 0s 806us/step - loss: 1.2148\n",
      "Epoch 121/500\n",
      "32/32 [==============================] - 0s 726us/step - loss: 1.1846\n",
      "Epoch 122/500\n",
      "32/32 [==============================] - 0s 785us/step - loss: 1.1772\n",
      "Epoch 123/500\n",
      "32/32 [==============================] - 0s 756us/step - loss: 1.1434\n",
      "Epoch 124/500\n",
      "32/32 [==============================] - 0s 700us/step - loss: 1.1231\n",
      "Epoch 125/500\n",
      "32/32 [==============================] - 0s 781us/step - loss: 1.0892\n",
      "Epoch 126/500\n",
      "32/32 [==============================] - 0s 704us/step - loss: 1.1034\n",
      "Epoch 127/500\n",
      "32/32 [==============================] - 0s 725us/step - loss: 1.0579\n",
      "Epoch 128/500\n",
      "32/32 [==============================] - 0s 739us/step - loss: 1.0404\n",
      "Epoch 129/500\n",
      "32/32 [==============================] - 0s 701us/step - loss: 1.0536\n",
      "Epoch 130/500\n",
      "32/32 [==============================] - 0s 850us/step - loss: 1.0031\n",
      "Epoch 131/500\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.9922\n",
      "Epoch 132/500\n",
      "32/32 [==============================] - 0s 760us/step - loss: 0.9803\n",
      "Epoch 133/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9939\n",
      "Epoch 134/500\n",
      "32/32 [==============================] - 0s 739us/step - loss: 0.9288\n",
      "Epoch 135/500\n",
      "32/32 [==============================] - 0s 661us/step - loss: 0.9424\n",
      "Epoch 136/500\n",
      "32/32 [==============================] - 0s 633us/step - loss: 0.9254\n",
      "Epoch 137/500\n",
      "32/32 [==============================] - 0s 741us/step - loss: 0.9119\n",
      "Epoch 138/500\n",
      "32/32 [==============================] - 0s 663us/step - loss: 0.8923\n",
      "Epoch 139/500\n",
      "32/32 [==============================] - 0s 681us/step - loss: 0.8864\n",
      "Epoch 140/500\n",
      "32/32 [==============================] - 0s 702us/step - loss: 0.8764\n",
      "Epoch 141/500\n",
      "32/32 [==============================] - 0s 805us/step - loss: 0.8455\n",
      "Epoch 142/500\n",
      "32/32 [==============================] - 0s 801us/step - loss: 0.8489\n",
      "Epoch 143/500\n",
      "32/32 [==============================] - 0s 846us/step - loss: 0.8468\n",
      "Epoch 144/500\n",
      "32/32 [==============================] - 0s 803us/step - loss: 0.8100\n",
      "Epoch 145/500\n",
      "32/32 [==============================] - 0s 797us/step - loss: 0.8135\n",
      "Epoch 146/500\n",
      "32/32 [==============================] - 0s 689us/step - loss: 0.8144\n",
      "Epoch 147/500\n",
      "32/32 [==============================] - 0s 641us/step - loss: 0.7700\n",
      "Epoch 148/500\n",
      "32/32 [==============================] - 0s 684us/step - loss: 0.7736\n",
      "Epoch 149/500\n",
      "32/32 [==============================] - 0s 664us/step - loss: 0.7526\n",
      "Epoch 150/500\n",
      "32/32 [==============================] - 0s 658us/step - loss: 0.7533\n",
      "Epoch 151/500\n",
      "32/32 [==============================] - 0s 732us/step - loss: 0.7463\n",
      "Epoch 152/500\n",
      "32/32 [==============================] - 0s 649us/step - loss: 0.7271\n",
      "Epoch 153/500\n",
      "32/32 [==============================] - 0s 696us/step - loss: 0.7285\n",
      "Epoch 154/500\n",
      "32/32 [==============================] - 0s 669us/step - loss: 0.7238\n",
      "Epoch 155/500\n",
      "32/32 [==============================] - 0s 645us/step - loss: 0.6961\n",
      "Epoch 156/500\n",
      "32/32 [==============================] - 0s 719us/step - loss: 0.7053\n",
      "Epoch 157/500\n",
      "32/32 [==============================] - 0s 654us/step - loss: 0.6838\n",
      "Epoch 158/500\n",
      "32/32 [==============================] - 0s 696us/step - loss: 0.6817\n",
      "Epoch 159/500\n",
      "32/32 [==============================] - 0s 683us/step - loss: 0.6720\n",
      "Epoch 160/500\n",
      "32/32 [==============================] - 0s 678us/step - loss: 0.6655\n",
      "Epoch 161/500\n",
      "32/32 [==============================] - 0s 682us/step - loss: 0.6527\n",
      "Epoch 162/500\n",
      "32/32 [==============================] - 0s 697us/step - loss: 0.6441\n",
      "Epoch 163/500\n",
      "32/32 [==============================] - 0s 723us/step - loss: 0.6420\n",
      "Epoch 164/500\n",
      "32/32 [==============================] - 0s 658us/step - loss: 0.6240\n",
      "Epoch 165/500\n",
      "32/32 [==============================] - 0s 671us/step - loss: 0.6294\n",
      "Epoch 166/500\n",
      "32/32 [==============================] - 0s 652us/step - loss: 0.6214\n",
      "Epoch 167/500\n",
      "32/32 [==============================] - 0s 685us/step - loss: 0.6205\n",
      "Epoch 168/500\n",
      "32/32 [==============================] - 0s 804us/step - loss: 0.5975\n",
      "Epoch 169/500\n",
      "32/32 [==============================] - 0s 681us/step - loss: 0.5985\n",
      "Epoch 170/500\n",
      "32/32 [==============================] - 0s 746us/step - loss: 0.5893\n",
      "Epoch 171/500\n",
      "32/32 [==============================] - 0s 723us/step - loss: 0.5891\n",
      "Epoch 172/500\n",
      "32/32 [==============================] - 0s 699us/step - loss: 0.5790\n",
      "Epoch 173/500\n",
      "32/32 [==============================] - 0s 802us/step - loss: 0.5706\n",
      "Epoch 174/500\n",
      "32/32 [==============================] - 0s 800us/step - loss: 0.5689\n",
      "Epoch 175/500\n",
      "32/32 [==============================] - 0s 850us/step - loss: 0.5549\n",
      "Epoch 176/500\n",
      "32/32 [==============================] - 0s 715us/step - loss: 0.5728\n",
      "Epoch 177/500\n",
      "32/32 [==============================] - 0s 679us/step - loss: 0.5489\n",
      "Epoch 178/500\n",
      "32/32 [==============================] - 0s 712us/step - loss: 0.5455\n",
      "Epoch 179/500\n",
      "32/32 [==============================] - 0s 703us/step - loss: 0.5462\n",
      "Epoch 180/500\n",
      "32/32 [==============================] - 0s 655us/step - loss: 0.5436\n",
      "Epoch 181/500\n",
      "32/32 [==============================] - 0s 686us/step - loss: 0.5353\n",
      "Epoch 182/500\n",
      "32/32 [==============================] - 0s 682us/step - loss: 0.5183\n",
      "Epoch 183/500\n",
      "32/32 [==============================] - 0s 695us/step - loss: 0.5189\n",
      "Epoch 184/500\n",
      "32/32 [==============================] - 0s 700us/step - loss: 0.5118\n",
      "Epoch 185/500\n",
      "32/32 [==============================] - 0s 639us/step - loss: 0.5190\n",
      "Epoch 186/500\n",
      "32/32 [==============================] - 0s 672us/step - loss: 0.5251\n",
      "Epoch 187/500\n",
      "32/32 [==============================] - 0s 719us/step - loss: 0.5126\n",
      "Epoch 188/500\n",
      "32/32 [==============================] - 0s 652us/step - loss: 0.5152\n",
      "Epoch 189/500\n",
      "32/32 [==============================] - 0s 745us/step - loss: 0.4880\n",
      "Epoch 190/500\n",
      "32/32 [==============================] - 0s 734us/step - loss: 0.4938\n",
      "Epoch 191/500\n",
      "32/32 [==============================] - 0s 731us/step - loss: 0.5028\n",
      "Epoch 192/500\n",
      "32/32 [==============================] - 0s 767us/step - loss: 0.4973\n",
      "Epoch 193/500\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.4877\n",
      "Epoch 194/500\n",
      "32/32 [==============================] - 0s 698us/step - loss: 0.4861\n",
      "Epoch 195/500\n",
      "32/32 [==============================] - 0s 781us/step - loss: 0.4911\n",
      "Epoch 196/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 686us/step - loss: 0.4816\n",
      "Epoch 197/500\n",
      "32/32 [==============================] - 0s 763us/step - loss: 0.4797\n",
      "Epoch 198/500\n",
      "32/32 [==============================] - 0s 685us/step - loss: 0.4638\n",
      "Epoch 199/500\n",
      "32/32 [==============================] - 0s 703us/step - loss: 0.4719\n",
      "Epoch 200/500\n",
      "32/32 [==============================] - 0s 761us/step - loss: 0.4711\n",
      "Epoch 201/500\n",
      "32/32 [==============================] - 0s 747us/step - loss: 0.4668\n",
      "Epoch 202/500\n",
      "32/32 [==============================] - 0s 658us/step - loss: 0.4608\n",
      "Epoch 203/500\n",
      "32/32 [==============================] - 0s 742us/step - loss: 0.4621\n",
      "Epoch 204/500\n",
      "32/32 [==============================] - 0s 674us/step - loss: 0.4463\n",
      "Epoch 205/500\n",
      "32/32 [==============================] - 0s 724us/step - loss: 0.4607\n",
      "Epoch 206/500\n",
      "32/32 [==============================] - 0s 691us/step - loss: 0.4477\n",
      "Epoch 207/500\n",
      "32/32 [==============================] - 0s 699us/step - loss: 0.4438\n",
      "Epoch 208/500\n",
      "32/32 [==============================] - 0s 739us/step - loss: 0.4456\n",
      "Epoch 209/500\n",
      "32/32 [==============================] - 0s 745us/step - loss: 0.4321\n",
      "Epoch 210/500\n",
      "32/32 [==============================] - 0s 695us/step - loss: 0.4369\n",
      "Epoch 211/500\n",
      "32/32 [==============================] - 0s 715us/step - loss: 0.4328\n",
      "Epoch 212/500\n",
      "32/32 [==============================] - 0s 673us/step - loss: 0.4365\n",
      "Epoch 213/500\n",
      "32/32 [==============================] - 0s 675us/step - loss: 0.4241\n",
      "Epoch 214/500\n",
      "32/32 [==============================] - 0s 704us/step - loss: 0.4322\n",
      "Epoch 215/500\n",
      "32/32 [==============================] - 0s 666us/step - loss: 0.4323\n",
      "Epoch 216/500\n",
      "32/32 [==============================] - 0s 712us/step - loss: 0.4308\n",
      "Epoch 217/500\n",
      "32/32 [==============================] - 0s 702us/step - loss: 0.4344\n",
      "Epoch 218/500\n",
      "32/32 [==============================] - 0s 700us/step - loss: 0.4276\n",
      "Epoch 219/500\n",
      "32/32 [==============================] - 0s 748us/step - loss: 0.4144\n",
      "Epoch 220/500\n",
      "32/32 [==============================] - 0s 686us/step - loss: 0.4142\n",
      "Epoch 221/500\n",
      "32/32 [==============================] - 0s 713us/step - loss: 0.4111\n",
      "Epoch 222/500\n",
      "32/32 [==============================] - 0s 735us/step - loss: 0.4128\n",
      "Epoch 223/500\n",
      "32/32 [==============================] - 0s 692us/step - loss: 0.4201\n",
      "Epoch 224/500\n",
      "32/32 [==============================] - 0s 707us/step - loss: 0.4197\n",
      "Epoch 225/500\n",
      "32/32 [==============================] - 0s 702us/step - loss: 0.4097\n",
      "Epoch 226/500\n",
      "32/32 [==============================] - 0s 660us/step - loss: 0.4200\n",
      "Epoch 227/500\n",
      "32/32 [==============================] - 0s 717us/step - loss: 0.4163\n",
      "Epoch 228/500\n",
      "32/32 [==============================] - 0s 698us/step - loss: 0.4078\n",
      "Epoch 229/500\n",
      "32/32 [==============================] - 0s 675us/step - loss: 0.4174\n",
      "Epoch 230/500\n",
      "32/32 [==============================] - 0s 720us/step - loss: 0.4043\n",
      "Epoch 231/500\n",
      "32/32 [==============================] - 0s 687us/step - loss: 0.3974\n",
      "Epoch 232/500\n",
      "32/32 [==============================] - 0s 693us/step - loss: 0.4020\n",
      "Epoch 233/500\n",
      "32/32 [==============================] - 0s 703us/step - loss: 0.4124\n",
      "Epoch 234/500\n",
      "32/32 [==============================] - 0s 723us/step - loss: 0.3948\n",
      "Epoch 235/500\n",
      "32/32 [==============================] - 0s 733us/step - loss: 0.4024\n",
      "Epoch 236/500\n",
      "32/32 [==============================] - 0s 795us/step - loss: 0.4066\n",
      "Epoch 237/500\n",
      "32/32 [==============================] - 0s 685us/step - loss: 0.3944\n",
      "Epoch 238/500\n",
      "32/32 [==============================] - 0s 733us/step - loss: 0.4030\n",
      "Epoch 239/500\n",
      "32/32 [==============================] - 0s 695us/step - loss: 0.3954\n",
      "Epoch 240/500\n",
      "32/32 [==============================] - 0s 783us/step - loss: 0.3888\n",
      "Epoch 241/500\n",
      "32/32 [==============================] - 0s 734us/step - loss: 0.3953\n",
      "Epoch 242/500\n",
      "32/32 [==============================] - 0s 688us/step - loss: 0.3800\n",
      "Epoch 243/500\n",
      "32/32 [==============================] - 0s 735us/step - loss: 0.3990\n",
      "Epoch 244/500\n",
      "32/32 [==============================] - 0s 704us/step - loss: 0.3988\n",
      "Epoch 245/500\n",
      "32/32 [==============================] - 0s 690us/step - loss: 0.3822\n",
      "Epoch 246/500\n",
      "32/32 [==============================] - 0s 710us/step - loss: 0.3997\n",
      "Epoch 247/500\n",
      "32/32 [==============================] - 0s 708us/step - loss: 0.3750\n",
      "Epoch 248/500\n",
      "32/32 [==============================] - 0s 730us/step - loss: 0.4003\n",
      "Epoch 249/500\n",
      "32/32 [==============================] - 0s 708us/step - loss: 0.3689\n",
      "Epoch 250/500\n",
      "32/32 [==============================] - 0s 699us/step - loss: 0.3888\n",
      "Epoch 251/500\n",
      "32/32 [==============================] - 0s 687us/step - loss: 0.3855\n",
      "Epoch 252/500\n",
      "32/32 [==============================] - 0s 741us/step - loss: 0.3860\n",
      "Epoch 253/500\n",
      "32/32 [==============================] - 0s 688us/step - loss: 0.3772\n",
      "Epoch 254/500\n",
      "32/32 [==============================] - 0s 826us/step - loss: 0.3913\n",
      "Epoch 255/500\n",
      "32/32 [==============================] - 0s 741us/step - loss: 0.3882\n",
      "Epoch 256/500\n",
      "32/32 [==============================] - 0s 721us/step - loss: 0.3899\n",
      "Epoch 257/500\n",
      "32/32 [==============================] - 0s 722us/step - loss: 0.3663\n",
      "Epoch 258/500\n",
      "32/32 [==============================] - 0s 741us/step - loss: 0.3760\n",
      "Epoch 259/500\n",
      "32/32 [==============================] - 0s 729us/step - loss: 0.3717\n",
      "Epoch 260/500\n",
      "32/32 [==============================] - 0s 772us/step - loss: 0.3639\n",
      "Epoch 261/500\n",
      "32/32 [==============================] - 0s 695us/step - loss: 0.3655\n",
      "Epoch 262/500\n",
      "32/32 [==============================] - 0s 772us/step - loss: 0.3776\n",
      "Epoch 263/500\n",
      "32/32 [==============================] - 0s 709us/step - loss: 0.3907\n",
      "Epoch 264/500\n",
      "32/32 [==============================] - 0s 707us/step - loss: 0.3653\n",
      "Epoch 265/500\n",
      "32/32 [==============================] - 0s 707us/step - loss: 0.3773\n",
      "Epoch 266/500\n",
      "32/32 [==============================] - 0s 726us/step - loss: 0.3687\n",
      "Epoch 267/500\n",
      "32/32 [==============================] - 0s 710us/step - loss: 0.3798\n",
      "Epoch 268/500\n",
      "32/32 [==============================] - 0s 779us/step - loss: 0.3615\n",
      "Epoch 269/500\n",
      "32/32 [==============================] - 0s 665us/step - loss: 0.3569\n",
      "Epoch 270/500\n",
      "32/32 [==============================] - 0s 757us/step - loss: 0.3711\n",
      "Epoch 271/500\n",
      "32/32 [==============================] - 0s 696us/step - loss: 0.3638\n",
      "Epoch 272/500\n",
      "32/32 [==============================] - 0s 705us/step - loss: 0.3853\n",
      "Epoch 273/500\n",
      "32/32 [==============================] - 0s 765us/step - loss: 0.3540\n",
      "Epoch 274/500\n",
      "32/32 [==============================] - 0s 723us/step - loss: 0.3648\n",
      "Epoch 275/500\n",
      "32/32 [==============================] - 0s 722us/step - loss: 0.3669\n",
      "Epoch 276/500\n",
      "32/32 [==============================] - 0s 729us/step - loss: 0.3741\n",
      "Epoch 277/500\n",
      "32/32 [==============================] - 0s 695us/step - loss: 0.3678\n",
      "Epoch 278/500\n",
      "32/32 [==============================] - 0s 818us/step - loss: 0.3606\n",
      "Epoch 279/500\n",
      "32/32 [==============================] - 0s 698us/step - loss: 0.3588\n",
      "Epoch 280/500\n",
      "32/32 [==============================] - 0s 732us/step - loss: 0.3628\n",
      "Epoch 281/500\n",
      "32/32 [==============================] - 0s 749us/step - loss: 0.3613\n",
      "Epoch 282/500\n",
      "32/32 [==============================] - 0s 704us/step - loss: 0.3695\n",
      "Epoch 283/500\n",
      "32/32 [==============================] - 0s 746us/step - loss: 0.3497\n",
      "Epoch 284/500\n",
      "32/32 [==============================] - 0s 729us/step - loss: 0.3556\n",
      "Epoch 285/500\n",
      "32/32 [==============================] - 0s 699us/step - loss: 0.3584\n",
      "Epoch 286/500\n",
      "32/32 [==============================] - 0s 719us/step - loss: 0.3615\n",
      "Epoch 287/500\n",
      "32/32 [==============================] - 0s 737us/step - loss: 0.3626\n",
      "Epoch 288/500\n",
      "32/32 [==============================] - 0s 819us/step - loss: 0.3641\n",
      "Epoch 289/500\n",
      "32/32 [==============================] - 0s 804us/step - loss: 0.3555\n",
      "Epoch 290/500\n",
      "32/32 [==============================] - 0s 686us/step - loss: 0.3576\n",
      "Epoch 291/500\n",
      "32/32 [==============================] - 0s 775us/step - loss: 0.3570\n",
      "Epoch 292/500\n",
      "32/32 [==============================] - 0s 795us/step - loss: 0.3526\n",
      "Epoch 293/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3564\n",
      "Epoch 294/500\n",
      "32/32 [==============================] - 0s 901us/step - loss: 0.3492\n",
      "Epoch 295/500\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3452\n",
      "Epoch 296/500\n",
      "32/32 [==============================] - 0s 832us/step - loss: 0.3653\n",
      "Epoch 297/500\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.3417\n",
      "Epoch 298/500\n",
      "32/32 [==============================] - 0s 796us/step - loss: 0.3495\n",
      "Epoch 299/500\n",
      "32/32 [==============================] - 0s 700us/step - loss: 0.3402\n",
      "Epoch 300/500\n",
      "32/32 [==============================] - 0s 760us/step - loss: 0.3554\n",
      "Epoch 301/500\n",
      "32/32 [==============================] - 0s 681us/step - loss: 0.3518\n",
      "Epoch 302/500\n",
      "32/32 [==============================] - 0s 793us/step - loss: 0.3487\n",
      "Epoch 303/500\n",
      "32/32 [==============================] - 0s 724us/step - loss: 0.3482\n",
      "Epoch 304/500\n",
      "32/32 [==============================] - 0s 682us/step - loss: 0.3499\n",
      "Epoch 305/500\n",
      "32/32 [==============================] - 0s 715us/step - loss: 0.3449\n",
      "Epoch 306/500\n",
      "32/32 [==============================] - 0s 703us/step - loss: 0.3381\n",
      "Epoch 307/500\n",
      "32/32 [==============================] - 0s 693us/step - loss: 0.3429\n",
      "Epoch 308/500\n",
      "32/32 [==============================] - 0s 711us/step - loss: 0.3445\n",
      "Epoch 309/500\n",
      "32/32 [==============================] - 0s 705us/step - loss: 0.3386\n",
      "Epoch 310/500\n",
      "32/32 [==============================] - 0s 697us/step - loss: 0.3477\n",
      "Epoch 311/500\n",
      "32/32 [==============================] - 0s 707us/step - loss: 0.3352\n",
      "Epoch 312/500\n",
      "32/32 [==============================] - 0s 683us/step - loss: 0.3557\n",
      "Epoch 313/500\n",
      "32/32 [==============================] - 0s 738us/step - loss: 0.3424\n",
      "Epoch 314/500\n",
      "32/32 [==============================] - 0s 686us/step - loss: 0.3453\n",
      "Epoch 315/500\n",
      "32/32 [==============================] - 0s 683us/step - loss: 0.3415\n",
      "Epoch 316/500\n",
      "32/32 [==============================] - 0s 673us/step - loss: 0.3379\n",
      "Epoch 317/500\n",
      "32/32 [==============================] - 0s 674us/step - loss: 0.3460\n",
      "Epoch 318/500\n",
      "32/32 [==============================] - 0s 676us/step - loss: 0.3434\n",
      "Epoch 319/500\n",
      "32/32 [==============================] - 0s 772us/step - loss: 0.3293\n",
      "Epoch 320/500\n",
      "32/32 [==============================] - 0s 673us/step - loss: 0.3498\n",
      "Epoch 321/500\n",
      "32/32 [==============================] - 0s 708us/step - loss: 0.3432\n",
      "Epoch 322/500\n",
      "32/32 [==============================] - 0s 768us/step - loss: 0.3325\n",
      "Epoch 323/500\n",
      "32/32 [==============================] - 0s 695us/step - loss: 0.3373\n",
      "Epoch 324/500\n",
      "32/32 [==============================] - 0s 723us/step - loss: 0.3418\n",
      "Epoch 325/500\n",
      "32/32 [==============================] - 0s 684us/step - loss: 0.3430\n",
      "Epoch 326/500\n",
      "32/32 [==============================] - 0s 686us/step - loss: 0.3278\n",
      "Epoch 327/500\n",
      "32/32 [==============================] - 0s 709us/step - loss: 0.3357\n",
      "Epoch 328/500\n",
      "32/32 [==============================] - 0s 673us/step - loss: 0.3319\n",
      "Epoch 329/500\n",
      "32/32 [==============================] - 0s 672us/step - loss: 0.3445\n",
      "Epoch 330/500\n",
      "32/32 [==============================] - 0s 764us/step - loss: 0.3539\n",
      "Epoch 331/500\n",
      "32/32 [==============================] - 0s 693us/step - loss: 0.3256\n",
      "Epoch 332/500\n",
      "32/32 [==============================] - 0s 683us/step - loss: 0.3412\n",
      "Epoch 333/500\n",
      "32/32 [==============================] - 0s 708us/step - loss: 0.3450\n",
      "Epoch 334/500\n",
      "32/32 [==============================] - 0s 683us/step - loss: 0.3363\n",
      "Epoch 335/500\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.3369\n",
      "Epoch 336/500\n",
      "32/32 [==============================] - 0s 721us/step - loss: 0.3288\n",
      "Epoch 337/500\n",
      "32/32 [==============================] - 0s 728us/step - loss: 0.3419\n",
      "Epoch 338/500\n",
      "32/32 [==============================] - 0s 721us/step - loss: 0.3270\n",
      "Epoch 339/500\n",
      "32/32 [==============================] - 0s 730us/step - loss: 0.3353\n",
      "Epoch 340/500\n",
      "32/32 [==============================] - 0s 706us/step - loss: 0.3230\n",
      "Epoch 341/500\n",
      "32/32 [==============================] - 0s 766us/step - loss: 0.3280\n",
      "Epoch 342/500\n",
      "32/32 [==============================] - 0s 713us/step - loss: 0.3338\n",
      "Epoch 343/500\n",
      "32/32 [==============================] - 0s 756us/step - loss: 0.3315\n",
      "Epoch 344/500\n",
      "32/32 [==============================] - 0s 687us/step - loss: 0.3409\n",
      "Epoch 345/500\n",
      "32/32 [==============================] - 0s 740us/step - loss: 0.3268\n",
      "Epoch 346/500\n",
      "32/32 [==============================] - 0s 724us/step - loss: 0.3251\n",
      "Epoch 347/500\n",
      "32/32 [==============================] - 0s 647us/step - loss: 0.3384\n",
      "Epoch 348/500\n",
      "32/32 [==============================] - 0s 714us/step - loss: 0.3190\n",
      "Epoch 349/500\n",
      "32/32 [==============================] - 0s 713us/step - loss: 0.3359\n",
      "Epoch 350/500\n",
      "32/32 [==============================] - 0s 672us/step - loss: 0.3282\n",
      "Epoch 351/500\n",
      "32/32 [==============================] - 0s 713us/step - loss: 0.3258\n",
      "Epoch 352/500\n",
      "32/32 [==============================] - 0s 671us/step - loss: 0.3228\n",
      "Epoch 353/500\n",
      "32/32 [==============================] - 0s 667us/step - loss: 0.3285\n",
      "Epoch 354/500\n",
      "32/32 [==============================] - 0s 687us/step - loss: 0.3177\n",
      "Epoch 355/500\n",
      "32/32 [==============================] - 0s 689us/step - loss: 0.3138\n",
      "Epoch 356/500\n",
      "32/32 [==============================] - 0s 690us/step - loss: 0.3222\n",
      "Epoch 357/500\n",
      "32/32 [==============================] - 0s 709us/step - loss: 0.3214\n",
      "Epoch 358/500\n",
      "32/32 [==============================] - 0s 722us/step - loss: 0.3264\n",
      "Epoch 359/500\n",
      "32/32 [==============================] - 0s 725us/step - loss: 0.3239\n",
      "Epoch 360/500\n",
      "32/32 [==============================] - 0s 752us/step - loss: 0.3227\n",
      "Epoch 361/500\n",
      "32/32 [==============================] - 0s 703us/step - loss: 0.3340\n",
      "Epoch 362/500\n",
      "32/32 [==============================] - 0s 742us/step - loss: 0.3323\n",
      "Epoch 363/500\n",
      "32/32 [==============================] - 0s 866us/step - loss: 0.3169\n",
      "Epoch 364/500\n",
      "32/32 [==============================] - 0s 711us/step - loss: 0.3151\n",
      "Epoch 365/500\n",
      "32/32 [==============================] - 0s 746us/step - loss: 0.3305\n",
      "Epoch 366/500\n",
      "32/32 [==============================] - 0s 693us/step - loss: 0.3166\n",
      "Epoch 367/500\n",
      "32/32 [==============================] - 0s 753us/step - loss: 0.3243\n",
      "Epoch 368/500\n",
      "32/32 [==============================] - 0s 792us/step - loss: 0.3198\n",
      "Epoch 369/500\n",
      "32/32 [==============================] - 0s 756us/step - loss: 0.3269\n",
      "Epoch 370/500\n",
      "32/32 [==============================] - 0s 749us/step - loss: 0.3237\n",
      "Epoch 371/500\n",
      "32/32 [==============================] - 0s 729us/step - loss: 0.3244\n",
      "Epoch 372/500\n",
      "32/32 [==============================] - 0s 661us/step - loss: 0.3229\n",
      "Epoch 373/500\n",
      "32/32 [==============================] - 0s 722us/step - loss: 0.3181\n",
      "Epoch 374/500\n",
      "32/32 [==============================] - 0s 685us/step - loss: 0.3174\n",
      "Epoch 375/500\n",
      "32/32 [==============================] - 0s 689us/step - loss: 0.3165\n",
      "Epoch 376/500\n",
      "32/32 [==============================] - 0s 757us/step - loss: 0.3233\n",
      "Epoch 377/500\n",
      "32/32 [==============================] - 0s 719us/step - loss: 0.3006\n",
      "Epoch 378/500\n",
      "32/32 [==============================] - 0s 735us/step - loss: 0.3117\n",
      "Epoch 379/500\n",
      "32/32 [==============================] - 0s 693us/step - loss: 0.3177\n",
      "Epoch 380/500\n",
      "32/32 [==============================] - 0s 713us/step - loss: 0.3184\n",
      "Epoch 381/500\n",
      "32/32 [==============================] - 0s 696us/step - loss: 0.3195\n",
      "Epoch 382/500\n",
      "32/32 [==============================] - 0s 724us/step - loss: 0.3037\n",
      "Epoch 383/500\n",
      "32/32 [==============================] - 0s 747us/step - loss: 0.3156\n",
      "Epoch 384/500\n",
      "32/32 [==============================] - 0s 765us/step - loss: 0.3100\n",
      "Epoch 385/500\n",
      "32/32 [==============================] - 0s 709us/step - loss: 0.3125\n",
      "Epoch 386/500\n",
      "32/32 [==============================] - 0s 733us/step - loss: 0.3055\n",
      "Epoch 387/500\n",
      "32/32 [==============================] - 0s 724us/step - loss: 0.3223\n",
      "Epoch 388/500\n",
      "32/32 [==============================] - 0s 712us/step - loss: 0.3044\n",
      "Epoch 389/500\n",
      "32/32 [==============================] - 0s 763us/step - loss: 0.3049\n",
      "Epoch 390/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 663us/step - loss: 0.3267\n",
      "Epoch 391/500\n",
      "32/32 [==============================] - 0s 714us/step - loss: 0.3080\n",
      "Epoch 392/500\n",
      "32/32 [==============================] - 0s 709us/step - loss: 0.3199\n",
      "Epoch 393/500\n",
      "32/32 [==============================] - 0s 650us/step - loss: 0.3154\n",
      "Epoch 394/500\n",
      "32/32 [==============================] - 0s 667us/step - loss: 0.3065\n",
      "Epoch 395/500\n",
      "32/32 [==============================] - 0s 693us/step - loss: 0.3142\n",
      "Epoch 396/500\n",
      "32/32 [==============================] - 0s 663us/step - loss: 0.3148\n",
      "Epoch 397/500\n",
      "32/32 [==============================] - 0s 684us/step - loss: 0.3039\n",
      "Epoch 398/500\n",
      "32/32 [==============================] - 0s 655us/step - loss: 0.3079\n",
      "Epoch 399/500\n",
      "32/32 [==============================] - 0s 654us/step - loss: 0.3154\n",
      "Epoch 400/500\n",
      "32/32 [==============================] - 0s 715us/step - loss: 0.3043\n",
      "Epoch 401/500\n",
      "32/32 [==============================] - 0s 723us/step - loss: 0.3002\n",
      "Epoch 402/500\n",
      "32/32 [==============================] - 0s 655us/step - loss: 0.3061\n",
      "Epoch 403/500\n",
      "32/32 [==============================] - 0s 675us/step - loss: 0.3098\n",
      "Epoch 404/500\n",
      "32/32 [==============================] - 0s 715us/step - loss: 0.3046\n",
      "Epoch 405/500\n",
      "32/32 [==============================] - 0s 695us/step - loss: 0.2991\n",
      "Epoch 406/500\n",
      "32/32 [==============================] - 0s 753us/step - loss: 0.3092\n",
      "Epoch 407/500\n",
      "32/32 [==============================] - 0s 642us/step - loss: 0.3134\n",
      "Epoch 408/500\n",
      "32/32 [==============================] - 0s 698us/step - loss: 0.3037\n",
      "Epoch 409/500\n",
      "32/32 [==============================] - 0s 697us/step - loss: 0.2967\n",
      "Epoch 410/500\n",
      "32/32 [==============================] - 0s 667us/step - loss: 0.3035\n",
      "Epoch 411/500\n",
      "32/32 [==============================] - 0s 742us/step - loss: 0.3066\n",
      "Epoch 412/500\n",
      "32/32 [==============================] - 0s 673us/step - loss: 0.3049\n",
      "Epoch 413/500\n",
      "32/32 [==============================] - 0s 685us/step - loss: 0.3041\n",
      "Epoch 414/500\n",
      "32/32 [==============================] - 0s 836us/step - loss: 0.3056\n",
      "Epoch 415/500\n",
      "32/32 [==============================] - 0s 758us/step - loss: 0.3096\n",
      "Epoch 416/500\n",
      "32/32 [==============================] - 0s 748us/step - loss: 0.2933\n",
      "Epoch 417/500\n",
      "32/32 [==============================] - 0s 800us/step - loss: 0.2894\n",
      "Epoch 418/500\n",
      "32/32 [==============================] - 0s 747us/step - loss: 0.3010\n",
      "Epoch 419/500\n",
      "32/32 [==============================] - 0s 816us/step - loss: 0.3041\n",
      "Epoch 420/500\n",
      "32/32 [==============================] - 0s 738us/step - loss: 0.2975\n",
      "Epoch 421/500\n",
      "32/32 [==============================] - 0s 772us/step - loss: 0.3146\n",
      "Epoch 422/500\n",
      "32/32 [==============================] - 0s 684us/step - loss: 0.2921\n",
      "Epoch 423/500\n",
      "32/32 [==============================] - 0s 648us/step - loss: 0.3063\n",
      "Epoch 424/500\n",
      "32/32 [==============================] - 0s 727us/step - loss: 0.2978\n",
      "Epoch 425/500\n",
      "32/32 [==============================] - 0s 655us/step - loss: 0.2902\n",
      "Epoch 426/500\n",
      "32/32 [==============================] - 0s 650us/step - loss: 0.2983\n",
      "Epoch 427/500\n",
      "32/32 [==============================] - 0s 690us/step - loss: 0.2957\n",
      "Epoch 428/500\n",
      "32/32 [==============================] - 0s 703us/step - loss: 0.3048\n",
      "Epoch 429/500\n",
      "32/32 [==============================] - 0s 658us/step - loss: 0.2871\n",
      "Epoch 430/500\n",
      "32/32 [==============================] - 0s 696us/step - loss: 0.2927\n",
      "Epoch 431/500\n",
      "32/32 [==============================] - 0s 673us/step - loss: 0.3023\n",
      "Epoch 432/500\n",
      "32/32 [==============================] - 0s 696us/step - loss: 0.2919\n",
      "Epoch 433/500\n",
      "32/32 [==============================] - 0s 717us/step - loss: 0.2922\n",
      "Epoch 434/500\n",
      "32/32 [==============================] - 0s 875us/step - loss: 0.3027\n",
      "Epoch 435/500\n",
      "32/32 [==============================] - 0s 830us/step - loss: 0.2903\n",
      "Epoch 436/500\n",
      "32/32 [==============================] - 0s 764us/step - loss: 0.2905\n",
      "Epoch 437/500\n",
      "32/32 [==============================] - 0s 741us/step - loss: 0.3031\n",
      "Epoch 438/500\n",
      "32/32 [==============================] - 0s 796us/step - loss: 0.2901\n",
      "Epoch 439/500\n",
      "32/32 [==============================] - 0s 763us/step - loss: 0.2909\n",
      "Epoch 440/500\n",
      "32/32 [==============================] - 0s 824us/step - loss: 0.2964\n",
      "Epoch 441/500\n",
      "32/32 [==============================] - 0s 820us/step - loss: 0.2979\n",
      "Epoch 442/500\n",
      "32/32 [==============================] - 0s 740us/step - loss: 0.2859\n",
      "Epoch 443/500\n",
      "32/32 [==============================] - 0s 813us/step - loss: 0.2837\n",
      "Epoch 444/500\n",
      "32/32 [==============================] - 0s 712us/step - loss: 0.3001\n",
      "Epoch 445/500\n",
      "32/32 [==============================] - 0s 736us/step - loss: 0.2841\n",
      "Epoch 446/500\n",
      "32/32 [==============================] - 0s 685us/step - loss: 0.2932\n",
      "Epoch 447/500\n",
      "32/32 [==============================] - 0s 772us/step - loss: 0.2838\n",
      "Epoch 448/500\n",
      "32/32 [==============================] - 0s 811us/step - loss: 0.3044\n",
      "Epoch 449/500\n",
      "32/32 [==============================] - 0s 769us/step - loss: 0.2881\n",
      "Epoch 450/500\n",
      "32/32 [==============================] - 0s 758us/step - loss: 0.2841\n",
      "Epoch 451/500\n",
      "32/32 [==============================] - 0s 820us/step - loss: 0.2983\n",
      "Epoch 452/500\n",
      "32/32 [==============================] - 0s 771us/step - loss: 0.2925\n",
      "Epoch 453/500\n",
      "32/32 [==============================] - 0s 704us/step - loss: 0.2894\n",
      "Epoch 454/500\n",
      "32/32 [==============================] - 0s 677us/step - loss: 0.2911\n",
      "Epoch 455/500\n",
      "32/32 [==============================] - 0s 666us/step - loss: 0.2779\n",
      "Epoch 456/500\n",
      "32/32 [==============================] - 0s 661us/step - loss: 0.2946\n",
      "Epoch 457/500\n",
      "32/32 [==============================] - 0s 638us/step - loss: 0.2930\n",
      "Epoch 458/500\n",
      "32/32 [==============================] - 0s 636us/step - loss: 0.2852\n",
      "Epoch 459/500\n",
      "32/32 [==============================] - 0s 693us/step - loss: 0.2934\n",
      "Epoch 460/500\n",
      "32/32 [==============================] - 0s 675us/step - loss: 0.2866\n",
      "Epoch 461/500\n",
      "32/32 [==============================] - 0s 696us/step - loss: 0.2843\n",
      "Epoch 462/500\n",
      "32/32 [==============================] - 0s 738us/step - loss: 0.2838\n",
      "Epoch 463/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2910\n",
      "Epoch 464/500\n",
      "32/32 [==============================] - 0s 737us/step - loss: 0.2879\n",
      "Epoch 465/500\n",
      "32/32 [==============================] - 0s 677us/step - loss: 0.2843\n",
      "Epoch 466/500\n",
      "32/32 [==============================] - 0s 732us/step - loss: 0.2844\n",
      "Epoch 467/500\n",
      "32/32 [==============================] - 0s 711us/step - loss: 0.2922\n",
      "Epoch 468/500\n",
      "32/32 [==============================] - 0s 698us/step - loss: 0.2849\n",
      "Epoch 469/500\n",
      "32/32 [==============================] - 0s 751us/step - loss: 0.2928\n",
      "Epoch 470/500\n",
      "32/32 [==============================] - 0s 764us/step - loss: 0.2857\n",
      "Epoch 471/500\n",
      "32/32 [==============================] - 0s 780us/step - loss: 0.2865\n",
      "Epoch 472/500\n",
      "32/32 [==============================] - 0s 728us/step - loss: 0.2882\n",
      "Epoch 473/500\n",
      "32/32 [==============================] - 0s 697us/step - loss: 0.2890\n",
      "Epoch 474/500\n",
      "32/32 [==============================] - 0s 731us/step - loss: 0.2775\n",
      "Epoch 475/500\n",
      "32/32 [==============================] - 0s 691us/step - loss: 0.2763\n",
      "Epoch 476/500\n",
      "32/32 [==============================] - 0s 686us/step - loss: 0.2765\n",
      "Epoch 477/500\n",
      "32/32 [==============================] - 0s 717us/step - loss: 0.2863\n",
      "Epoch 478/500\n",
      "32/32 [==============================] - 0s 700us/step - loss: 0.2836\n",
      "Epoch 479/500\n",
      "32/32 [==============================] - 0s 713us/step - loss: 0.2821\n",
      "Epoch 480/500\n",
      "32/32 [==============================] - 0s 734us/step - loss: 0.2818\n",
      "Epoch 481/500\n",
      "32/32 [==============================] - 0s 668us/step - loss: 0.2855\n",
      "Epoch 482/500\n",
      "32/32 [==============================] - 0s 787us/step - loss: 0.2890\n",
      "Epoch 483/500\n",
      "32/32 [==============================] - 0s 714us/step - loss: 0.2788\n",
      "Epoch 484/500\n",
      "32/32 [==============================] - 0s 758us/step - loss: 0.2852\n",
      "Epoch 485/500\n",
      "32/32 [==============================] - 0s 845us/step - loss: 0.2730\n",
      "Epoch 486/500\n",
      "32/32 [==============================] - 0s 787us/step - loss: 0.2892\n",
      "Epoch 487/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 804us/step - loss: 0.2766\n",
      "Epoch 488/500\n",
      "32/32 [==============================] - 0s 755us/step - loss: 0.2808\n",
      "Epoch 489/500\n",
      "32/32 [==============================] - 0s 744us/step - loss: 0.2818\n",
      "Epoch 490/500\n",
      "32/32 [==============================] - 0s 844us/step - loss: 0.2938\n",
      "Epoch 491/500\n",
      "32/32 [==============================] - 0s 740us/step - loss: 0.2852\n",
      "Epoch 492/500\n",
      "32/32 [==============================] - 0s 792us/step - loss: 0.2855\n",
      "Epoch 493/500\n",
      "32/32 [==============================] - 0s 734us/step - loss: 0.2721\n",
      "Epoch 494/500\n",
      "32/32 [==============================] - 0s 732us/step - loss: 0.2848\n",
      "Epoch 495/500\n",
      "32/32 [==============================] - 0s 799us/step - loss: 0.2835\n",
      "Epoch 496/500\n",
      "32/32 [==============================] - 0s 702us/step - loss: 0.2754\n",
      "Epoch 497/500\n",
      "32/32 [==============================] - 0s 786us/step - loss: 0.2958\n",
      "Epoch 498/500\n",
      "32/32 [==============================] - 0s 670us/step - loss: 0.2799\n",
      "Epoch 499/500\n",
      "32/32 [==============================] - 0s 763us/step - loss: 0.2727\n",
      "Epoch 500/500\n",
      "32/32 [==============================] - 0s 831us/step - loss: 0.2761\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18a135ac0>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(new_inputs, ys, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a67a919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_preds = model1(new_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a916c4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 16, 3, 10, 49, 5, 65, 26, 49, 16, 10, 3, 49, 65, 3]\n",
      "[17, 17, 2, 10, 50, 5, 65, 26, 50, 17, 10, 2, 50, 65, 2]\n"
     ]
    }
   ],
   "source": [
    "show_diff(new_preds, ys, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8e0ae3",
   "metadata": {},
   "source": [
    "# mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f0194304",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7953d342",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "656eff33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f066c244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3b06c39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "850adea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x18b0322b0>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[0, :, :])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b37bd06",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "39b932a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ca6d5004",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(loss=loss_fn,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c7c0bc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2635 - accuracy: 0.9253\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 2s 951us/step - loss: 0.1185 - accuracy: 0.9651\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 2s 933us/step - loss: 0.0793 - accuracy: 0.9762\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 2s 915us/step - loss: 0.0602 - accuracy: 0.9818\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 2s 912us/step - loss: 0.0446 - accuracy: 0.9866\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 2s 974us/step - loss: 0.0365 - accuracy: 0.9891\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 2s 955us/step - loss: 0.0284 - accuracy: 0.9909\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0234 - accuracy: 0.9927\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0195 - accuracy: 0.9940\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0146 - accuracy: 0.9955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18abaddc0>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "eebe7ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 676us/step - loss: 0.0767 - accuracy: 0.9803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07667867094278336, 0.9803000092506409]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "cac5e83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(x_test[5:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2056fc09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       "array([[ -9.798481 ,   7.2124596,  -7.8057575,  -8.272958 ,  -3.7423503,\n",
       "        -14.336856 , -13.287978 ,   2.3670194,  -3.8577309,  -9.113962 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bed63434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db71b19b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
